{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Baseline Experiment 1\n",
    "\n",
    "Train model from scratch for each subject. \n",
    "\n",
    "Model: BSFShallowNet\n",
    "\n",
    "Dataset: BCI Competitin IV 2a, BCNI2014001 via MOABB library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "C:\\Users\\mengz\\anaconda3\\envs\\hyperBCI\\Lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from numpy import multiply\n",
    "from braindecode.preprocessing import (Preprocessor,\n",
    "                                       exponential_moving_standardize,\n",
    "                                       preprocess)\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "import torch\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "from braindecode.util import set_random_seeds\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib.lines import Line2D\n",
    "# from braindecode.visualization import plot_confusion_matrix\n",
    "\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "from braindecode.datasets.base import EEGWindowsDataset\n",
    "from braindecode.preprocessing.windowers import _create_windows_from_events\n",
    "import numpy as np\n",
    "import mne\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=list(range(1, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mengz\\anaconda3\\envs\\hyperBCI\\Lib\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.moabb.MOABBDataset at 0x227e1ea5f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cut_hz = 4.  # low cut frequency for filtering\n",
    "high_cut_hz = 38.  # high cut frequency for filtering\n",
    "# Parameters for exponential moving standardization\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "# Factor to convert from V to uV\n",
    "factor = 1e6\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
    "    Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n",
    "                 factor_new=factor_new, init_block_size=init_block_size)\n",
    "]\n",
    "\n",
    "# Transform the data\n",
    "preprocess(dataset, preprocessors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Compute Windows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "# Calculate the trial start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    preload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(window_set, target_trial_num):\n",
    "    new_ds_lst = []\n",
    "    \n",
    "    for ds in window_set.datasets:\n",
    "        cur_run_trial_num = len(ds.metadata)\n",
    "        if target_trial_num > cur_run_trial_num:\n",
    "            new_ds_lst.append(ds)\n",
    "            target_trial_num -= cur_run_trial_num\n",
    "        else:\n",
    "            new_ds_lst.append(EEGWindowsDataset(ds.raw, ds.metadata[:target_trial_num], description=ds.description[:target_trial_num]))\n",
    "            break\n",
    "\n",
    "    return BaseConcatDataset(new_ds_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune for holdout subject set; Pre-train with data from all other subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results'))\n",
    "exp_name = f'baseline_2_2_pretrain'\n",
    "\n",
    "### ---------- Pre-training parameters ----------\n",
    "lr = 0.07 * 0.01\n",
    "weight_decay = 0\n",
    "batch_size = 64\n",
    "n_epochs = 30\n",
    "\n",
    "splitted_by_subj = windows_dataset.split('subject')\n",
    "\n",
    "data_amount_step = 20\n",
    "results_columns = ['valid_accuracy',]\n",
    "dict_results = {}\n",
    "\n",
    "for holdout_subj_id in range(1, 10):\n",
    "    \n",
    "    print(f'Hold out data from subject {holdout_subj_id}')\n",
    "    \n",
    "    ### ---------- Split dataset into pre-train set and fine-tune (holdout) set ----------\n",
    "    pre_train_set = BaseConcatDataset([splitted_by_subj.get(f'{i}') for i in range(1, 10) if i != holdout_subj_id])\n",
    "    fine_tune_set = BaseConcatDataset([splitted_by_subj.get(f'{holdout_subj_id}'),])\n",
    "\n",
    "    ### ---------- Split pre-train set into pre-train-train set and pre-train-test set ----------\n",
    "    pre_train_train_set_lst = []\n",
    "    pre_train_test_set_lst = []\n",
    "    pre_train_test_set_size = 1 # runs\n",
    "    for key, val in pre_train_set.split('subject').items():\n",
    "        subj_splitted_lst_by_run = list(val.split('run').values())\n",
    "        pre_train_train_set_lst.extend(subj_splitted_lst_by_run[:-pre_train_test_set_size])\n",
    "        pre_train_test_set_lst.extend(subj_splitted_lst_by_run[-pre_train_test_set_size:])\n",
    "    \n",
    "    pre_train_train_set = BaseConcatDataset(pre_train_train_set_lst)\n",
    "    pre_train_test_set = BaseConcatDataset(pre_train_test_set_lst)\n",
    "\n",
    "    ### ---------- Pre-training ----------\n",
    "    cuda = torch.cuda.is_available() \n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "    if cuda:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    seed = 20200220\n",
    "    set_random_seeds(seed=seed, cuda=cuda)\n",
    "    \n",
    "    n_classes = 4\n",
    "    classes = list(range(n_classes))\n",
    "    # Extract number of chans and time steps from dataset\n",
    "    n_chans = windows_dataset[0][0].shape[0]\n",
    "    input_window_samples = windows_dataset[0][0].shape[1]\n",
    "    \n",
    "    cur_model = ShallowFBCSPNet(\n",
    "        n_chans,\n",
    "        n_classes,\n",
    "        input_window_samples=input_window_samples,\n",
    "        final_conv_length='auto',\n",
    "    )\n",
    "    \n",
    "    cur_clf = EEGClassifier(\n",
    "        cur_model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(pre_train_test_set),  # using valid_set for validation\n",
    "        optimizer__lr=lr,\n",
    "        optimizer__weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "        ],\n",
    "        device=device,\n",
    "        classes=classes,\n",
    "        warm_start=False\n",
    "    )\n",
    "\n",
    "    print(f'Pre-training model with data from all subjects but subject {holdout_subj_id}')\n",
    "    _ = cur_clf.fit(pre_train_train_set, y=None, epochs=n_epochs)\n",
    "\n",
    "    cur_clf.save_params(f_params=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_model.pkl'), \n",
    "                        f_optimizer=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_opt.pkl'), \n",
    "                        f_history=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_history.json'))\n",
    "\n",
    "    ### ---------- Split fine tune set into fine tune-train set and fine tune-valid set ----------\n",
    "    finetune_splitted_lst_by_run = list(fine_tune_set.split('run').values())\n",
    "    finetune_subj_train_set = BaseConcatDataset(finetune_splitted_lst_by_run[:-1])\n",
    "    finetune_subj_valid_set = BaseConcatDataset(finetune_splitted_lst_by_run[-1:])\n",
    "    \n",
    "    ### Baseline accuracy on the finetune_valid set\n",
    "    finetune_valid_predicted = cur_clf.predict(finetune_subj_valid_set)\n",
    "    finetune_valid_true = np.array(finetune_subj_valid_set.get_metadata().target)\n",
    "    finetune_baseline_correct = np.equal(finetune_valid_predicted, finetune_valid_true)\n",
    "    finetune_baseline_acc = np.sum(finetune_baseline_correct) / len(finetune_baseline_correct)\n",
    "    print(f'Before finetuning for subject {holdout_subj_id}, the baseline accuracy is {finetune_baseline_acc}')\n",
    "\n",
    "    ### ---------- Fine tuning ----------\n",
    "    dict_subj_results = {0: finetune_baseline_acc}\n",
    "\n",
    "    ### Finetune with different amount of new data\n",
    "    finetune_trials_num = len(finetune_subj_train_set.get_metadata())\n",
    "    for finetune_training_data_amount in np.arange(1, finetune_trials_num // data_amount_step) * data_amount_step:\n",
    "\n",
    "        ## Get current finetune samples\n",
    "        cur_finetune_subj_train_subset = get_subset(finetune_subj_train_set, finetune_training_data_amount)\n",
    "\n",
    "        finetune_model = ShallowFBCSPNet(\n",
    "            n_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto',\n",
    "        )\n",
    "\n",
    "        ### ---------- Fine tune parameters ----------\n",
    "        finetune_lr = 0.07 * 0.01\n",
    "        finetune_weight_decay = 0\n",
    "        finetune_batch_size = int(min(finetune_training_data_amount // 2, 64))\n",
    "        finetune_n_epochs = 20\n",
    "        \n",
    "        new_clf = EEGClassifier(\n",
    "            finetune_model,\n",
    "            criterion=torch.nn.NLLLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            train_split=predefined_split(finetune_subj_valid_set), \n",
    "            optimizer__lr=finetune_lr,\n",
    "            optimizer__weight_decay=finetune_weight_decay,\n",
    "            batch_size=finetune_batch_size,\n",
    "            callbacks=[\n",
    "                \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=finetune_n_epochs - 1)),\n",
    "            ],\n",
    "            device=device,\n",
    "            classes=classes,\n",
    "        )\n",
    "        new_clf.initialize()\n",
    "        \n",
    "        ## Load pretrained model\n",
    "        new_clf.load_params(f_params=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_model.pkl'), \n",
    "                            f_optimizer=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_opt.pkl'), \n",
    "                            f_history=os.path.join(results_dir, f'{exp_name}_without_subj_{holdout_subj_id}_history.json'))\n",
    "\n",
    "        ## Continue training / finetuning\n",
    "        print(f'Fine tuning model for subject {holdout_subj_id} with {finetune_training_data_amount} trials')\n",
    "        _ = new_clf.partial_fit(cur_finetune_subj_train_subset, y=None, epochs=finetune_n_epochs)\n",
    "\n",
    "        ## Get results after fine tuning\n",
    "        df = pd.DataFrame(new_clf.history[:, results_columns], columns=results_columns,\n",
    "                          # index=new_clf.history[:, 'epoch'],\n",
    "                         )\n",
    "\n",
    "        cur_final_acc = np.mean(df.tail(5).valid_accuracy)\n",
    "        dict_subj_results.update({finetune_training_data_amount: cur_final_acc})\n",
    "\n",
    "    dict_results.update({holdout_subj_id: dict_subj_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ShallowFBCSPNet_BNCI2014_001_finetuning_2'\n",
    "file_path = os.path.join(results_dir, f'{file_name}.pkl')\n",
    "\n",
    "with open(f'{results_dir}\\\\{file_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "#     with open(file_path, 'rb') as f:\n",
    "#         baseline_2_1 = pickle.load(f)\n",
    "#     print(\"Dictionary loaded successfully.\")\n",
    "# else:\n",
    "#     print(f\"Error: File '{file_path}' does not exist or is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(dict_results)\n",
    "display(df_results)\n",
    "\n",
    "subject_averaged_df = df_results.mean(axis=1)\n",
    "# Calculate the standard error of the mean\n",
    "std_err_df = df_results.sem(axis=1)\n",
    "# Calculate the confidence interval (95% confidence level)\n",
    "conf_interval_df = stats.t.interval(0.95, len(df_results.columns) - 1, loc=subject_averaged_df, scale=std_err_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "for subj_id, subj_res in dict_results.items():\n",
    "    ax1.plot(subj_res.keys(), subj_res.values(), label=f'Subject {subj_id}')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Amount of fine tuning data (trials, 4 secs each)')\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "\n",
    "ax2.plot(subject_averaged_df, label='Subject averaged')\n",
    "ax2.fill_between(subject_averaged_df.index, conf_interval_df[0], conf_interval_df[1], color='b', alpha=0.3, label='95% CI')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Amount of fine tuning data (trials, 4 secs each)')\n",
    "\n",
    "plt.suptitle('ShallowFBCSPNet on BNCI2014_001 Dataset \\n Fine-tuning (using each subject as holdout)')\n",
    "\n",
    "plt.savefig(os.path.join(results_dir, f'{file_name}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
